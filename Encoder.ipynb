{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "import torch.nn.functional as F\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get real! Now we know attention, which is of course \"all you need\" ;) We will \n",
    "# implement encoder properly with in pytorch\n",
    "# we use einops to simplify matrix handling syntax among other things, to install, uncomment:\n",
    "# !pip3 install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # einsum in early versions can be too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1204e-01, 3.3179e-01, 3.7844e-01, 7.2353e-01, 4.4927e-01, 1.1372e-01,\n",
       "         2.7527e-01, 2.0844e-01, 3.0714e-01, 1.5609e-01],\n",
       "        [4.5294e-01, 9.9741e-01, 3.5441e-01, 2.1147e-01, 1.8738e-01, 7.6277e-01,\n",
       "         5.6122e-01, 9.7209e-04, 2.1788e-01, 8.6360e-01],\n",
       "        [3.4282e-01, 6.3288e-01, 5.9995e-01, 5.8601e-01, 7.1222e-02, 5.2544e-01,\n",
       "         3.2955e-01, 2.8433e-01, 3.7653e-01, 6.3157e-01],\n",
       "        [8.2733e-01, 4.8969e-01, 4.8225e-01, 1.3652e-02, 5.5434e-01, 2.6493e-01,\n",
       "         2.8982e-01, 6.8646e-01, 1.6388e-01, 4.6974e-01],\n",
       "        [5.5633e-01, 5.6522e-01, 9.8118e-01, 4.0900e-01, 2.4492e-01, 1.8387e-01,\n",
       "         2.1073e-01, 7.3774e-01, 1.6522e-01, 6.4002e-01],\n",
       "        [5.3758e-01, 8.9740e-01, 8.6875e-01, 8.8043e-01, 1.6907e-01, 3.2457e-01,\n",
       "         7.3095e-01, 7.8696e-01, 7.5072e-01, 4.4058e-01],\n",
       "        [9.2194e-01, 4.5239e-01, 8.8996e-01, 9.5824e-01, 6.2432e-01, 6.7026e-01,\n",
       "         7.6904e-01, 5.4834e-01, 5.6674e-01, 9.1058e-01],\n",
       "        [8.5816e-01, 5.0199e-01, 5.0019e-01, 9.2626e-01, 3.1948e-01, 9.6178e-01,\n",
       "         9.2905e-01, 7.1913e-01, 2.6952e-01, 8.6636e-02],\n",
       "        [4.7680e-01, 5.1278e-01, 1.4902e-01, 2.2101e-02, 1.5706e-01, 8.4604e-01,\n",
       "         2.7758e-01, 7.8745e-01, 8.0730e-01, 9.2942e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "BLOCK:\n",
    "batch of tensors of embedding dim n -> self attention + id\n",
    "-> layer norm -> MLP for each in batch (just plain default) + id\n",
    "-> layer norm\n",
    "'''\n",
    "sentence_len = 9 # batch size\n",
    "emb_dim = 10 \n",
    "num_heads = 3\n",
    "input_batch = torch.rand(sentence_len, emb_dim)\n",
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V):\n",
    "    ''' Functional implementation for scaled dot product attention formula'''\n",
    "    dot_prod = torch.matmul(Q, torch.transpose(K, -2, -1)) #swap last 2 dims, regardless of batch dim\n",
    "    K_dim = K.size(-1)\n",
    "    softmax = F.softmax(dot_prod/math.sqrt(K_dim), dim = -1)\n",
    "    attention = torch.matmul(softmax, V)\n",
    "    return attention\n",
    "\n",
    "class SelfAttentionMultiheadedWide(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads):\n",
    "        super().__init__()\n",
    "        # we want to output the same dim as embedding to enable residual connection\n",
    "        # init 3 matrices all the same\n",
    "        self.M_Q, self.M_V, self.M_K = \\\n",
    "            [nn.Linear(emb_dim, emb_dim*num_heads, bias=False) for _ in range(3)]\n",
    "        \n",
    "        self.M_merge_heads = nn.Linear(emb_dim*num_heads, emb_dim, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # get Q, K, V\n",
    "        Q = self.M_Q(x)\n",
    "        K = self.M_K(x)\n",
    "        V = self.M_V(x)\n",
    "        multi_att = attention(Q, K, V)\n",
    "        return self.M_merge_heads(multi_att)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = SelfAttention(emb_dim, num_heads)\n",
    "x = attention_layer(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0544,  0.1883, -0.0467, -0.3533,  0.0380, -0.1548, -0.0787, -0.2424,\n",
       "          0.0815, -0.0482],\n",
       "        [-0.0539,  0.1869, -0.0471, -0.3514,  0.0367, -0.1543, -0.0785, -0.2426,\n",
       "          0.0806, -0.0478],\n",
       "        [-0.0539,  0.1880, -0.0472, -0.3528,  0.0371, -0.1549, -0.0784, -0.2432,\n",
       "          0.0812, -0.0480],\n",
       "        [-0.0536,  0.1882, -0.0479, -0.3532,  0.0360, -0.1555, -0.0780, -0.2444,\n",
       "          0.0817, -0.0481],\n",
       "        [-0.0527,  0.1890, -0.0477, -0.3537,  0.0364, -0.1552, -0.0781, -0.2444,\n",
       "          0.0816, -0.0481],\n",
       "        [-0.0533,  0.1897, -0.0476, -0.3542,  0.0377, -0.1554, -0.0786, -0.2441,\n",
       "          0.0811, -0.0480],\n",
       "        [-0.0536,  0.1890, -0.0465, -0.3529,  0.0385, -0.1545, -0.0791, -0.2424,\n",
       "          0.0806, -0.0479],\n",
       "        [-0.0542,  0.1894, -0.0477, -0.3542,  0.0375, -0.1558, -0.0786, -0.2441,\n",
       "          0.0812, -0.0480],\n",
       "        [-0.0542,  0.1886, -0.0484, -0.3538,  0.0359, -0.1564, -0.0779, -0.2453,\n",
       "          0.0816, -0.0481]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
