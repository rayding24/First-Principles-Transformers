# Transformers implemented and explained from scratch, culminating in (smaller scale) GPT3 and Vision Transformer (ViT)

First Principles Transformers-Vanilla2SOTA


# Biblio:
The author wish to express sincere gratitude towards the following sources, without which this journey would have taken much longer and been more difficult.

## Original papers:

## Folders:
_minGPT and _fullGPT are mostly adapted from, respectively,  
karpathy/minGPT:https://github.com/karpathy/minGPT/blob/master  
tingkai-zhang/openai-gpt-pytorch (which is modified from HuggingFace's gpt models):  
https://github.com/tingkai-zhang/openai-gpt-pytorch

## The following material has been very inspirational and helpful for understanding transformers better:
http://peterbloem.nl/blog/transformers  
http://jalammar.github.io/illustrated-transformer/  
http://juditacs.github.io/2018/12/27/masked-attention.html   

## These material has been interesting to explore:
https://nlp.seas.harvard.edu/2018/04/03/attention.html   
https://kazemnejad.com/blog/transformer_architecture_positional_encoding/   
https://stackoverflow.com/questions/50747947/embedding-in-pytorch   
https://www.reddit.com/r/MachineLearning/comments/cttefo/d_positional_encoding_in_transformer/   
