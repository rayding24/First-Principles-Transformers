{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is often the case that we only want to use part of a input sequence. In the case of a sentence, we would like to \"cover\" later parts of the sentence for next token prediction, otherwise it will be trivial for the model to grab the prediction token from the input sentence. TODO: expand this on training algorithm that necessitates this, and why use -inf to achieve this, cool comparison trick to make masks; For now straight to the point -- train masked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are we having from the data??\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
